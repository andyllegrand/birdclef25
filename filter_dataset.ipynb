{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/birdclef2025/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoModelForImageClassification, AutoImageProcessor, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback, get_cosine_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "NUM_CLASSES = 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 148905\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "class BirdTrainDatasetPrecomputed(Dataset):\n",
    "    def __init__(self, counts_df, labels_df, data_path='data/precomputed_spectrograms/spectrograms', use_cutmix=True, use_masking=True, num_classes = 206, sample_random_ms = False):\n",
    "        self.path = data_path\n",
    "        self.use_cutmix = use_cutmix\n",
    "        self.use_masking = use_masking\n",
    "        self.num_classes = num_classes\n",
    "        self.sample_random_ms = sample_random_ms\n",
    "        self.labels_df_indexed = labels_df.set_index('file_path')\n",
    "        self.labels_df = labels_df\n",
    "        self.counts_df = counts_df\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.sample_random_ms:\n",
    "            return len(self.counts_df)\n",
    "        return len(self.labels_df) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.get_path_and_label(idx)\n",
    "        spec = torch.load(path)\n",
    "\n",
    "        if self.use_cutmix and random.random() < 0.5:\n",
    "            mix_path, mix_label = self.get_path_and_label(-1)\n",
    "            mix_spec = torch.load(mix_path)\n",
    "\n",
    "            if self.use_masking:\n",
    "                spec = self.xy_masking(spec)\n",
    "                mix_spec = self.xy_masking(mix_spec)\n",
    "\n",
    "            spec, label = self.horizontal_cutmix(spec, label, mix_spec, mix_label)\n",
    "\n",
    "        else:\n",
    "            if self.use_masking:\n",
    "                spec = self.xy_masking(spec)\n",
    "            label = F.one_hot(torch.tensor(label), self.num_classes).float()\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": spec,\n",
    "            \"labels\": label,\n",
    "            \"file_name\": str(path),\n",
    "            \"index\": idx\n",
    "        }\n",
    "\n",
    "    def get_path_and_label(self, idx = -1):\n",
    "        if idx == -1:\n",
    "            idx = random.randint(0, self.__len__() - 1)\n",
    "        \n",
    "        if self.sample_random_ms:\n",
    "            dir_path = Path(self.counts_df.iloc[idx]['file_path'])\n",
    "            count = self.counts_df.iloc[idx]['count']\n",
    "            filename = random.randint(0, count - 1)\n",
    "            path = dir_path / f\"{filename}.pt\"\n",
    "            label = self.labels_df_indexed.loc[str(path)]['label']\n",
    "            return path, label\n",
    "        else:\n",
    "            return self.labels_df.iloc[idx]['file_path'], self.labels_df.iloc[idx]['label']\n",
    "\n",
    "    def xy_masking(self, spec, num_x_masks=2, num_y_masks=1, max_width=10, max_height=10):\n",
    "        \"\"\"\n",
    "        Applies vertical (x) and horizontal (y) rectangular zero-masks to the spectrogram.\n",
    "        \"\"\"\n",
    "        cloned = spec.clone()\n",
    "        _, height, width = cloned.shape\n",
    "\n",
    "        # Apply x-masks (vertical)\n",
    "        for _ in range(num_x_masks):\n",
    "            w = random.randint(1, max_width)\n",
    "            x = random.randint(0, max(0, width - w))\n",
    "            cloned[:, :, x:x+w] = 0.0\n",
    "\n",
    "        # Apply y-masks (horizontal)\n",
    "        for _ in range(num_y_masks):\n",
    "            h = random.randint(1, max_height)\n",
    "            y = random.randint(0, max(0, height - h))\n",
    "            cloned[:, y:y+h, :] = 0.0\n",
    "\n",
    "        return cloned\n",
    "\n",
    "    def horizontal_cutmix(self, spec1, label1, spec2, label2, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Mix two spectrograms horizontally (along the time axis),\n",
    "        and create soft labels using torch.nn.functional.one_hot.\n",
    "        \"\"\"\n",
    "        _, h, w = spec1.shape\n",
    "        cut_point = random.randint(int(0.3 * w), int(0.7 * w))\n",
    "        lam = cut_point / w\n",
    "\n",
    "        # Concatenate spectrograms along the time axis (width)\n",
    "        new_spec = torch.cat((spec1[:, :, :cut_point], spec2[:, :, cut_point:]), dim=2)\n",
    "\n",
    "        # Convert scalar labels to one-hot vectors\n",
    "        label1_onehot = F.one_hot(torch.tensor(label1), num_classes=self.num_classes).float()\n",
    "        label2_onehot = F.one_hot(torch.tensor(label2), num_classes=self.num_classes).float()\n",
    "\n",
    "        # Mix the labels\n",
    "        mixed_label = lam * label1_onehot + (1 - lam) * label2_onehot\n",
    "\n",
    "        return new_spec, mixed_label\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv('/home/andy/Desktop/BirdClef/customSED/data/precomputed_spectrograms/labels.csv')\n",
    "counts_df = pd.read_csv('/home/andy/Desktop/BirdClef/customSED/data/precomputed_spectrograms/counts.csv')\n",
    "\n",
    "full_ds = BirdTrainDatasetPrecomputed(\n",
    "    counts_df=counts_df,\n",
    "    labels_df=labels_df,\n",
    "    data_path='/home/andy/Desktop/BirdClef/customSED/data/precomputed_spectrograms/spectrograms',\n",
    "    use_cutmix=False,\n",
    "    use_masking=False,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    sample_random_ms=False\n",
    ")\n",
    "\n",
    "print(f\"Full dataset size: {len(full_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold0/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold1/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold2/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold3/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold4/checkpoint-12000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold0/checkpoint-12000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold1/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold2/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold3/checkpoint-14000\n",
      "loaded model /home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold4/checkpoint-13000\n"
     ]
    }
   ],
   "source": [
    "# load model ensemble\n",
    "paths = [\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold0/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold1/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold2/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold3/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/facebook/regnet-y-008_fold4/checkpoint-12000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold0/checkpoint-12000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold1/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold2/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold3/checkpoint-14000\",\n",
    "  \"/home/andy/Desktop/BirdClef/customSED/ensemble_runs/google/efficientnet-b2_fold4/checkpoint-13000\",\n",
    "]\n",
    "\n",
    "models = []\n",
    "for path in paths:\n",
    "  model = AutoModelForImageClassification.from_pretrained(path)\n",
    "  model.eval()\n",
    "  model.to(\"cpu\")\n",
    "  models.append(model)\n",
    "  print(f\"loaded model {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing RegNetForImageClassification: 100%|██████████| 373/373 [03:05<00:00,  2.01it/s]\n",
      "Inferencing RegNetForImageClassification: 100%|██████████| 373/373 [03:08<00:00,  1.98it/s]\n",
      "Inferencing RegNetForImageClassification: 100%|██████████| 373/373 [03:03<00:00,  2.04it/s]\n",
      "Inferencing RegNetForImageClassification: 100%|██████████| 373/373 [03:13<00:00,  1.93it/s]\n",
      "Inferencing RegNetForImageClassification: 100%|██████████| 373/373 [03:16<00:00,  1.90it/s]\n",
      "Inferencing EfficientNetForImageClassification: 100%|██████████| 373/373 [04:24<00:00,  1.41it/s]\n",
      "Inferencing EfficientNetForImageClassification: 100%|██████████| 373/373 [04:37<00:00,  1.35it/s]\n",
      "Inferencing EfficientNetForImageClassification: 100%|██████████| 373/373 [04:41<00:00,  1.33it/s]\n",
      "Inferencing EfficientNetForImageClassification: 100%|██████████| 373/373 [04:39<00:00,  1.34it/s]\n",
      "Inferencing EfficientNetForImageClassification: 100%|██████████| 373/373 [04:39<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through models, throw on gpu, runs inference and create a df of logits. Do for all models\n",
    "models_logits = []\n",
    "batch_size = 400\n",
    "N = len(full_ds)\n",
    "\n",
    "for model in models:\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Pre‐allocate a (N, NUM_CLASSES) array for this model’s logits\n",
    "    this_logits = np.zeros((N, NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "    # Iterate over the dataset in chunks of `batch_size`\n",
    "    for start_idx in tqdm(range(0, N, batch_size), desc=f\"Inferencing {model.__class__.__name__}\"):\n",
    "        end_idx = min(start_idx + batch_size, N)\n",
    "        batch_indices = list(range(start_idx, end_idx))\n",
    "\n",
    "        # Stack all pixel_values for indices [start_idx : end_idx]\n",
    "        # Each full_ds[i]['pixel_values'] is (C, H, W), so stacking makes (B, C, H, W)\n",
    "        batch_tensor = torch.stack(\n",
    "            [ full_ds[i][\"pixel_values\"] for i in batch_indices ],\n",
    "            dim=0\n",
    "        ).to(device)  # shape: (batch_size, C, H, W)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=batch_tensor)\n",
    "            logits_batch = outputs.logits.cpu().numpy()  # shape: (batch_size, NUM_CLASSES)\n",
    "\n",
    "        # Store the logits into the correct rows of this_logits\n",
    "        this_logits[start_idx:end_idx, :] = logits_batch\n",
    "\n",
    "    # Append and free GPU memory\n",
    "    models_logits.append(this_logits)\n",
    "    model.to(\"cpu\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 148905, 207)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(models_logits).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 427\n",
    "for i in range(start, start + 10):\n",
    "    model = models[0]\n",
    "    spec = full_ds[i][\"pixel_values\"].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=spec)\n",
    "        logits = outputs.logits.cpu().numpy()\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "    \n",
    "    stored_pred = np.argmax(models_logits[0][i], axis=0)\n",
    "    true_label = np.argmax(full_ds[i][\"labels\"].numpy())\n",
    "    \n",
    "    print(f\"Model prediction for sample {i}: {pred[0]}, stored prediction: {stored_pred}, true label: {true_label}\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which classes have less samples then a threshold\n",
    "threshold = 8\n",
    "class_counts = labels_df['label'].value_counts()\n",
    "rare_classes = class_counts[class_counts < threshold].index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratgey 1: Average the logits from all models. take max label. If it does not match the label, then classify it as \"no-call\"\n",
    "\n",
    "# 1.1) Average the logits and get per‐example argmax:\n",
    "#stacked = np.stack(models_logits, axis=0)  # shape (n_models, N, NUM_CLASSES)\n",
    "#avg_logits = np.mean(stacked, axis=0)     # shape (N, NUM_CLASSES)\n",
    "#final_predictions = np.argmax(avg_logits, axis=1)  # shape (N,)\n",
    "final_predictions = np.argmax(models_logits[0], axis=1)\n",
    "\n",
    "# softmax\n",
    "#softmax = np.exp(models_logits[0]) / np.sum(np.exp(models_logits[0]), axis=1, keepdims=True)\n",
    "\n",
    "# 1.2) Pull out the true labels as a NumPy array\n",
    "true_labels = labels_df['label'].to_numpy()  # shape (N,)\n",
    "\n",
    "# 1.3) Make a copy of true_labels so we can override mismatches:\n",
    "new_targets = true_labels.copy()  # shape (N,)\n",
    "\n",
    "# 1.4) Define “no‐call” as the last index (NUM_CLASSES-1)\n",
    "NO_CALL_CLASS = NUM_CLASSES - 1\n",
    "\n",
    "# 1.5) Find where prediction ≠ true_label\n",
    "mismatch_mask = (final_predictions != true_labels)\n",
    "\n",
    "protect_rare = np.isin(true_labels, rare_classes)    # True for all i whose true label is rare\n",
    "mismatch_mask[protect_rare] = False\n",
    "\n",
    "# 1.6) Set those to NO_CALL_CLASS\n",
    "new_targets[mismatch_mask] = NO_CALL_CLASS\n",
    "\n",
    "# 1.7) Dump into a new DataFrame column and save to CSV\n",
    "new_labels_df = labels_df.copy()\n",
    "new_labels_df['label'] = new_targets\n",
    "new_labels_df.to_csv('/home/andy/Desktop/BirdClef/customSED/data/precomputed_spectrograms/filtered_labels_base_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.8765\n"
     ]
    }
   ],
   "source": [
    "# print overall accuracy\n",
    "accuracy = accuracy_score(true_labels, final_predictions)\n",
    "print(f\"Overall accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels_ds label statistics:\n",
      "  Max:  4105\n",
      "  Min:  2\n",
      "  Mean: 595.80\n",
      "  Std:  768.75\n",
      "\n",
      "Relabelled_ds label statistics:\n",
      "  Max:  15549\n",
      "  Min:  2\n",
      "  Mean: 601.70\n",
      "  Std:  1266.22\n",
      "\n",
      "Relabelled_ds (no no-call) label statistics:\n",
      "  Max:  3923\n",
      "  Min:  2\n",
      "  Mean: 527.34\n",
      "  Std:  699.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View some basic ds stats\n",
    "def print_label_stats(df, name=\"Dataset\"):\n",
    "    label_counts = df['label'].value_counts()\n",
    "    max_count = label_counts.max()\n",
    "    min_count = label_counts.min()\n",
    "    mean_count = label_counts.mean()\n",
    "    std_count = label_counts.std()\n",
    "\n",
    "    print(f\"{name} label statistics:\")\n",
    "    print(f\"  Max:  {max_count}\")\n",
    "    print(f\"  Min:  {min_count}\")\n",
    "    print(f\"  Mean: {mean_count:.2f}\")\n",
    "    print(f\"  Std:  {std_count:.2f}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Print stats for training and validation datasets\n",
    "print_label_stats(labels_df, \"Labels_ds\")\n",
    "print_label_stats(new_labels_df, \"Relabelled_ds\")\n",
    "\n",
    "# print stats for new_labels w/o no-call\n",
    "no_call_mask = new_labels_df['label'] != NO_CALL_CLASS\n",
    "print_label_stats(new_labels_df[no_call_mask], \"Relabelled_ds (no no-call)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdclef2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
